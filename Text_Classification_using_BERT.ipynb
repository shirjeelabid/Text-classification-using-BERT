{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSdJxZSzYUiH",
        "outputId": "3fa56791-fb6b-4006-b9ff-9e44d9c535d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.1)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30534 sha256=a52ed9678ebac3b6bcec3739bf2eeb4560493359179beaeffd8b9e64477ad8de\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/a4/72/df07592cea3ae06b5e846f5e52262f8b16748e829ca354b7df\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19472 sha256=b6d74909369013b98b3c0eaf8fed4d5a05f5ba7a8d301a25ed827ada498c6315\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/f3/85/b8cf1d8bfe55dc2ece0f1fcd4e91d6f8fc7b59ff3fd75329e1\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7911 sha256=d546a88fca7cafd2574d274837f3fe76caaaf2d34232aea9d47e42c067f2da13\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/26/e9/df16869ccbd4abf517f1ff3be9a2c7ee5c5980fc87eea04fb1\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "import math\n",
        "\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEmHP29VYVJt",
        "outputId": "83a5c648-356e-49a5-dd1d-57db2c5a88b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_reviews = pd.read_csv(\"/content/sample_data/IMDB_Dataset.csv\")\n",
        "print(f\"Null: {movie_reviews.isnull().values.any()}\")\n",
        "print(f\"shape: {movie_reviews.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3_XFk4kYlHj",
        "outputId": "4976d25e-0042-4a81-bd3c-01cff0e8378c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null: False\n",
            "shape: (50000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ],
      "metadata": {
        "id": "YuikZ2MUbI-j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(sen):\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "7YV9nKM9bPxp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = []\n",
        "sentences = list(movie_reviews['review'])\n",
        "for sen in sentences:\n",
        "    reviews.append(preprocess_text(sen))"
      ],
      "metadata": {
        "id": "YpopfFgFba1I"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(movie_reviews.columns.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om09a9vGbd49",
        "outputId": "75b8f685-e674-4b89-d014-4c7e7021cfa3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['review' 'sentiment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_reviews.sentiment.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j4rh3M_bhQ3",
        "outputId": "09af9d5f-751c-49e8-f5d7-9dcc63be3348"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['positive', 'negative'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = movie_reviews['sentiment']\n",
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
      ],
      "metadata": {
        "id": "_UUjB8eAbktQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Review sample:\\n {reviews[10]}\")\n",
        "print(f\"Review sentiment: {y[10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s935E3nEbocU",
        "outputId": "d5d7ec25-5ffc-4be1-b65c-73bf243252c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review sample:\n",
            " Phil the Alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines At first it was very odd and pretty funny but as the movie progressed didn find the jokes or oddness funny anymore Its low budget film thats never problem in itself there were some pretty interesting characters but eventually just lost interest imagine this film would appeal to stoner who is currently partaking For something similar but better try Brother from another planet \n",
            "Review sentiment: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
      ],
      "metadata": {
        "id": "zGoF6nf7brPB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.tokenize(\"don't try to be so sentimental or so judgemental\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRYCnOkybxDO",
        "outputId": "45be6042-a3db-4085-be27-d05f77f889ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['don', \"'\", 't', 'try', 'to', 'be', 'so', 'sentimental', 'or', 'so', 'judgement', '##al']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"don't try to be so sentimental or so judgemental\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rofwjBgcRax",
        "outputId": "5c6e3549-b17f-46d5-e9c8-81ca153d6815"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2123, 1005, 1056, 3046, 2000, 2022, 2061, 23069, 2030, 2061, 16646, 2389]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_reviews(text_reviews):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))"
      ],
      "metadata": {
        "id": "xyyqEpYlcUgF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_reviews = [tokenize_reviews(review) for review in reviews]"
      ],
      "metadata": {
        "id": "onXmYizicXLB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_with_len = [[review, y[i], len(review)]\n",
        "                 for i, review in enumerate(tokenized_reviews)]"
      ],
      "metadata": {
        "id": "58W-8bGEcZt8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(reviews_with_len)"
      ],
      "metadata": {
        "id": "QDjolxXLdGq8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_with_len.sort(key=lambda x: x[2])"
      ],
      "metadata": {
        "id": "VeXJQz8VdJYr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_reviews_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]"
      ],
      "metadata": {
        "id": "P_RmzAwXdMAP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_reviews_labels, output_types=(tf.int32, tf.int32))"
      ],
      "metadata": {
        "id": "5v6599rZdSL3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
      ],
      "metadata": {
        "id": "I5Qp9tAfdUpV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(batched_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu7MSEO7dXFh",
        "outputId": "bac08f7a-8657-4fb1-a6b6-a66a67acae36"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 21), dtype=int32, numpy=\n",
              " array([[ 3191,  1996,  2338,  5293,  1996,  3185,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 3078,  5436,  3078,  3257,  3532,  7613,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2054,  5896,  2054,  2466,  2054,  6752,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2062, 23873,  3993,  2062, 11259,  2172,  2172,  2062, 14888,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2023,  3185,  2003,  6659,  2021,  2009,  2038,  2070,  2204,\n",
              "          3896,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 1045,  2876,  9278,  2023,  2028,  2130,  2006,  7922, 12635,\n",
              "          2305,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 8235,  1998,  3048,  4616,  2011,  3419,  2457, 27727,  1998,\n",
              "          2848, 16133,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 1045,  3246,  2023,  2177,  1997,  2143, 11153,  2196,  2128,\n",
              "         15908,  2015,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 7918, 14674,  7662,  2003,  6581,  2003,  2023,  2143,  2002,\n",
              "          3084, 17160,  2450,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [11861,  1996, 21442,  6895,  3238,  2515,  2210, 22759,  6198,\n",
              "          1998,  3185,  2087, 12487,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2023,  2003,  2307,  3185,  2205,  2919,  2009,  2003,  2025,\n",
              "          2800,  2006,  2188,  2678,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2017,  2488,  5454,  2703,  2310, 25032,  8913,  8159,  2130,\n",
              "          2065,  2017,  2031,  3427,  2009,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2053,  7615,  5236,  3185,  3772,  2779,  2030,  4788,  9000,\n",
              "          2053,  3168,  2012,  2035, 13558,  2009,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 1045,  2123,  2113,  2339,  2066,  2023,  3185,  2061,  2092,\n",
              "          2021,  2196,  2131,  5458,  1997,  3666,  2009,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2074,  2293,  1996,  6970, 13068,  2090,  2048,  2307,  3494,\n",
              "          1997,  2754,  3898,  2310,  3593,  2102,  6287,  5974,     0,\n",
              "             0,     0,     0],\n",
              "        [ 7615,  2023,  3185,  2003,  5263,  2003,  6659,  2200, 17727,\n",
              "          3217,  3676,  3468,  2919,  7613,  3257,  2025,  2298,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2146, 11771,  1038,  8523,  8458,  6633,  3560,  2196,  2031,\n",
              "          2042,  2061,  5580,  2000,  2156,  4566,  6495,  4897,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2023,  2003,  2204,  2143,  2023,  2003,  2200,  6057,  2664,\n",
              "          2044,  2023,  2143,  2045,  2020,  2053,  2204,  8471,  3152,\n",
              "             0,     0,     0],\n",
              "        [ 2235,  3077,  2792,  3425,  2003,  1996,  2190,  2792,  1997,\n",
              "          2235,  3077,  2009,  2026,  5440,  2792,  1997,  2235,  3077,\n",
              "             0,     0,     0],\n",
              "        [ 5587,  2023,  2210, 17070,  2000,  2115,  2862,  1997,  6209,\n",
              "         24945,  2009, 26354, 28394,  2102,  6057,  1998,  2203, 27242,\n",
              "             0,     0,     0],\n",
              "        [ 1037,  7244,  3185,  2009,  2003,  2440,  1997,  6699,  1998,\n",
              "          6919,  3772,  2071,  2031,  2938,  2083,  2009,  2117,  2051,\n",
              "             0,     0,     0],\n",
              "        [ 2235,  3077,  2792,  3425,  2003,  1996,  2190,  2792,  1997,\n",
              "          2235,  3077,  2009,  2026,  5440,  2792,  1997,  2235,  3077,\n",
              "             0,     0,     0],\n",
              "        [ 7078, 10392,  3649,  2360,  2876,  2079,  2023,  2104,  9250,\n",
              "          3185,  1996,  3425,  2009, 17210,  3422,  2009,  2085, 10392,\n",
              "             0,     0,     0],\n",
              "        [ 2023,  2003,  1996, 15764,  3185,  2544,  1997,  8429, 24905,\n",
              "         17988,  7659,  2498,  2021,  2045,  2024,  2053, 13842,  5312,\n",
              "             0,     0,     0],\n",
              "        [ 1037,  2033,  6491, 11124,  6774,  2143,  2008,  5121,  7906,\n",
              "          2115,  3086,  3841, 13196,  2003, 17160,  1998, 26103,  2000,\n",
              "          3422,     0,     0],\n",
              "        [ 6283,  2009,  2007,  2035,  2026,  2108,  5409,  3185,  2412,\n",
              "         10597, 21985,  2393,  2033,  2009,  2001,  2008,  2919,  3404,\n",
              "          2033,     0,     0],\n",
              "        [ 1037,  5790,  1997,  2515,  2025,  4088,  2000,  4671,  2129,\n",
              "         10634,  2139, 24128,  1998, 21660,  2135,  2919,  2023,  3185,\n",
              "          2003,     0,     0],\n",
              "        [ 2005,  5760,  7788,  4393,  8808,  2498,  2064, 12826,  2000,\n",
              "          1996, 11056,  3152,  3811, 16755,  2169,  1998,  2296,  2028,\n",
              "          1997,  2068,     0],\n",
              "        [ 7244,  2092,  2856, 10828,  1997, 10904,  2402,  2472,  3135,\n",
              "          2293,  2466,  2007, 10958,  8428, 10102,  1999,  1996,  4281,\n",
              "          4276,  3773,     0],\n",
              "        [ 2023,  2003,  6659,  3185,  2123,  5949,  2115,  2769,  2006,\n",
              "          2009,  2123,  2130,  3422,  2009,  2005,  2489,  2008,  2035,\n",
              "          2031,  2000,  2360],\n",
              "        [ 2028,  1997,  1996,  4569, 15580,  2102,  5691,  2081,  1999,\n",
              "          3522,  2086,  2204, 23191,  5436,  1998, 11813,  6370,  2191,\n",
              "          2023,  2028,  4438],\n",
              "        [ 2307,  3185,  2926,  1996,  2189,  3802,  2696,  2508,  2012,\n",
              "          2197,  2023,  8847,  6702,  2043,  2017,  2031,  2633,  2179,\n",
              "          2008,  2569,  2619]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 0, 0, 1, 1, 0, 1, 0], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\n",
        "TEST_BATCHES = TOTAL_BATCHES // 10\n",
        "batched_dataset.shuffle(TOTAL_BATCHES)\n",
        "test_data = batched_dataset.take(TEST_BATCHES)\n",
        "train_data = batched_dataset.skip(TEST_BATCHES)"
      ],
      "metadata": {
        "id": "kz3gopcpdZP5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationModel(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 embedding_dimensions=128,\n",
        "                 cnn_filters=50,\n",
        "                 dnn_units=512,\n",
        "                 model_output_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"text_model\"):\n",
        "        super(TextClassificationModel, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocabulary_size,\n",
        "                                          embedding_dimensions)\n",
        "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=2,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=3,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=4,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if model_output_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=model_output_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        l = self.embedding(inputs)\n",
        "        l_1 = self.cnn_layer1(l) \n",
        "        l_1 = self.pool(l_1) \n",
        "        l_2 = self.cnn_layer2(l) \n",
        "        l_2 = self.pool(l_2)\n",
        "        l_3 = self.cnn_layer3(l)\n",
        "        l_3 = self.pool(l_3) \n",
        "        \n",
        "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1)\n",
        "        concatenated = self.dense_1(concatenated)\n",
        "        concatenated = self.dropout(concatenated, training)\n",
        "        model_output = self.last_dense(concatenated)\n",
        "        \n",
        "        return model_output"
      ],
      "metadata": {
        "id": "ULOfG1ukdegP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_LENGTH = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "CNN_FILTERS = 100\n",
        "DNN_UNITS = 256\n",
        "OUTPUT_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 6"
      ],
      "metadata": {
        "id": "cCETwHS-dlwN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_model = TextClassificationModel(vocabulary_size=VOCAB_LENGTH,\n",
        "                        embedding_dimensions=EMB_DIM,\n",
        "                        cnn_filters=CNN_FILTERS,\n",
        "                        dnn_units=DNN_UNITS,\n",
        "                        model_output_classes=OUTPUT_CLASSES,\n",
        "                        dropout_rate=DROPOUT_RATE)"
      ],
      "metadata": {
        "id": "l2PDcaj_dwo1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if OUTPUT_CLASSES == 2:\n",
        "    text_model.compile(loss=\"binary_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "else:\n",
        "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "metadata": {
        "id": "jxDxNXVcdxXl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_model.fit(train_data, epochs=NB_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXn90yn9d0t9",
        "outputId": "db92c48f-ddca-4d97-bac6-791bb40dfffc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "1407/1407 [==============================] - 129s 84ms/step - loss: 0.3042 - accuracy: 0.8662\n",
            "Epoch 2/6\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.1240 - accuracy: 0.9554\n",
            "Epoch 3/6\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0676 - accuracy: 0.9752\n",
            "Epoch 4/6\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0409 - accuracy: 0.9849\n",
            "Epoch 5/6\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0210 - accuracy: 0.9925\n",
            "Epoch 6/6\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0141 - accuracy: 0.9950\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4918c07df0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = text_model.evaluate(test_data)\n",
        "print(f\"Test evaluation results: {results}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-wG3tZzd4cc",
        "outputId": "47bd9b9c-7919-4691-a228-c9c70aa21035"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "156/156 [==============================] - 16s 99ms/step - loss: 0.5482 - accuracy: 0.8994\n",
            "Test evaluation results: [0.5482016801834106, 0.8994390964508057]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AZRhW7sYfCfF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}